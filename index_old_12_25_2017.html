
<!DOCTYPE html>
<html>
<head>
	<title>Avner May's homepage</title>
	<link rel="stylesheet" type="text/css" href="style.css" />
</head>
<body>

<div id="content">
<div id="photograph"><img src="pictures/Avner_May_Picture.jpg" alt="Picture of me" /></div>

<h1>Avner May</h1>
<h2>Contact information</h2>
<dl>
	<dt>E-mail</dt><dd>&lt;first name&gt;&lt;last name&gt;[at]cs.columbia.edu</dd> 
	<dt>Columbia Mailing Address</dt>
	<dd>
		<address>
			1214 Amsterdam Ave<br />
			450 Computer Science Building, Mailbox #100<br />
			New York, NY 10027
		</address>
	</dd> 
	<dt>Columbia Office</dt><dd>701 CEPSR</dd>
</dl>
<h2>About me</h2>
I am a PhD student in the <a href="http://www.cs.columbia.edu">Computer Science</a> department of Columbia University, where my advisor is <a href="http://www.cs.columbia.edu/~mcollins/">Prof. Michael Collins</a>. Prior to that, I was a Software Development Engineer at Microsoft for two years, living in Seattle, WA.  I graduated in 2009 from Harvard College, where I majored in Mathematics, with a minor in Computer Science. I am originally from Potomac, MD.<br />
Here is a link to my <a href="files/Avner_May_CV_website.pdf">resume</a> <i>(updated 1/31/2017)</i>.

<h2>Research Interests</h2>
My main research areas are in Machine Learning and Speech Recognition. Specifically, I have been working on acoustic modeling, which is a large-scale multi-class classification problem important in speech recognition systems. Most recently, I have focused on scaling kernel methods to this domain using approximation techniques. Although kernel methods have been extensively studied, and have a strong theoretical foundation, there has been relatively little success scaling these methods to large-scale problems like speech recognition and computer vision. Currently, deep learning methods are the state of the art in these domains.  I am interested in better understanding the differences between these two families of models, as well as improving these methods.<br /><br />
Prior to working on machine learning/acoustic modeling, I did two years of research in social network analysis, advised by <a href="http://www.cs.columbia.edu/~augustin/">Prof. Augustin Chaintreau</a>; I studied whether social networks like Facebook or Twitter are efficient systems for delivering content of interest to their users (2011-2013).

<h2>Other Interests</h2>
I love most things that involve being active and outdoors - running, biking, snowboarding, hiking, camping, and basically anything in the mountains.  I love fruits and vegetables, and am very interested in food systems and nutrition, and how they affect our health and the environment.  I am interested in the ways in which the fields of machine learning and neuroscience can learn from and help one another.  For example, could understanding how the brain processes speech help create better speech recognition systems?  Additionally, I am interested in how technology and machine learning can be applied to domains such as health and education.

<h2>Papers</h2>
<dl id="papers">
	<dt><a href="https://arxiv.org/pdf/1701.03577v1.pdf">Kernel Approximation Methods for Speech Recognition</a></dt>
		<dd>A. May, A.B. Garakani, Z. Lu, D. Guo, K. Liu, A. Bellet, L. Fan, M. Collins, D. Hsu, B. Kingsbury, M. Picheny, F. Sha</dd>
		<dd><em>arXiv 2017 (in submission to JMLR)</em></dd>
	<dt><a href="files/ICASSP_2016_Compact_Kernels.pdf">Compact Kernel Models for Acoustic Modeling via Random Feature Selection</a></dt>
		<dd>A. May, M. Collins, D. Hsu, B. Kingsbury</dd>
		<dd><em>ICASSP 2016</em></dd>
	<dt><a href="files/ICASSP_2016_Comparison_DNNs_Kernels.pdf">A Comparison Between Deep Neural Nets and Kernel Acoustic Models for Speech Recognition</a></dt>
		<dd>Z. Lu, D. Guo, A.B. Garakani, K. Liu, A. May, A. Bellet, L. Fan, M. Collins, B. Kingsbury, M. Picheny, F. Sha</dd>
		<dd><em>ICASSP 2016</em></dd>
	<dt>Compact Models for Large-scale Non-linear Learning via Random Feature Selection</dt>
		<dd>A. May, M. Collins, D. Hsu, B. Kingsbury</dd>
		<dd><em>NIPS 2015 Feature Extraction Workshop.</em></dd>
	<dt><a href="https://arxiv.org/pdf/1411.4000v1.pdf">How to Scale Up Kernel Methods to Be As Good As Deep Neural Nets</a></dt>
		<dd>A. May, Z. Lu, K. Lu, A. Garakani, D. Guo, A. Bellet, L. Fan, F. Sha, M. Collins, B. Kingsbury</dd>
		<dd><em>arXiv 2014</em></dd>
	<dt><a href="files/Sigmetrics2014_Filter_and_Follow.pdf">Filter &#38; Follow: How Social Media Foster Content Curation</a></dt>
		<dd>A. May, A. Chaintreau, N. Korula, S. Lattanzi</dd>
		<dd><em>SIGMETRICS 2014</em></dd>
</dl>

<h2>Posters and Presentations</h2>
<dl id="papers">
  <dt>NIPS 2015 Feature Extraction Workshop, Montreal, Canada, Dec. 11, 2015.</dt>
  <dt>SANE 2015 (Speech and Audio in the Northeast), New York, NY, Oct. 22, 2015.</dt>
  <dt>NYML 2015 (New York Machine Learning Symposium), New York, NY, Mar. 13, 2015.</dt>
	<dt>Workshop on Social Computing and User Generated Content @ The 2013 ACM Conference on Electronic Commerce (ACM-EC 2013), Philadelphia, PA, June 16, 2013.</dt>
	<dt>New York Computer Science and Economics Day (NYCE), New York, NY, Dec. 3rd 2012.</dt>
	<dt>Interdisciplinary Workshop on Information and Decision in Social Networks (WIDS), Cambridge, MA, Nov. 8-9, 2012.</dt>
</dl>

<h2>Internships</h2>
<dl id="papers">
  <dt>Summer 2015: Google Research, New York, NY.</dt>
  <dt>Summer 2014: Microsoft Research, Redmond, WA.</dt>
</dl>


</div> <!-- content -->

</body>
</html>
